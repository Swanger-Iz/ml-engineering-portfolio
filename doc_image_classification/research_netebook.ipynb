{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbcf482",
   "metadata": {},
   "source": [
    "# Fine-Tuning + Inference API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a19020",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных. Для обучения использован поднабор RVL-CDIP (тестовая часть), так как официальный train set недоступен. Разделение выполнено стратифицированно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362a43a",
   "metadata": {},
   "source": [
    "### Создание датасета для тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310fb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096e709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['invoice', 'letter', 'email', 'news_article']\n",
    "number_of_files = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('data')\n",
    "# os.mkdir('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a516b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('data', 'train')\n",
    "test_path = os.path.join('data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93a9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ilgiz/ml-engineering-portfolio/doc_image_classification'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir(os.path.join('..', '..'))\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(dest_path)\n",
    "# for i in range(len(classes)):\n",
    "#     os.mkdir(classes[i])\n",
    "\n",
    "# os.chdir(os.path.join('..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "189d4bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilgiz/ml-engineering-portfolio/doc_image_classification\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join('..', '..'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "859f8a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ilgiz/ml-engineering-portfolio/doc_image_classification'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir(os.path.join(src_path, classes[0]))[0]\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b70dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(train_path, classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/invoice/ti16311152.tif'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file = os.listdir(os.path.join(test_path, classes[0]))[0]\n",
    "# shutil.copy(os.path.join(test_path, classes[0], file), os.path.join(train_path, classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e16c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in classes:\n",
    "#     for n in range(number_of_files):\n",
    "#         file = os.listdir(os.path.join(src_path, c))[n]\n",
    "#         shutil.copy(os.path.join(src_path, c, file), os.path.join(dest_path, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc5fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: invoice | amount of objects: 2000\n",
      "Class: letter | amount of objects: 2000\n",
      "Class: email | amount of objects: 2000\n",
      "Class: news_article | amount of objects: 2000\n"
     ]
    }
   ],
   "source": [
    "for c in classes:\n",
    "    print(f'Class: {c} | amount of objects: {len(os.listdir(os.path.join(train_path, c)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8ae8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ti16311152.tif'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(test_path, classes[0]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981f59b",
   "metadata": {},
   "source": [
    "### Создание `transform` и своего класса `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbfb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5d18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = v2.Compose([\n",
    "    v2.ToImage(),    # Конвертируем PIL -> image\n",
    "    v2.ToDtype(torch.float32, scale=True),   # Масштабируем [0, 255] -> [0, 1]\n",
    "    v2.Resize((224, 224), antialias=True), \n",
    "    v2.RandomAffine(degrees=3, translate=(.05, .05), scale=(.95, 1.05)),    # лёгкий поворот + сдвиг + масштаб\n",
    "    v2.GaussianNoise(mean=.0, sigma=.01),\n",
    "    v2.Normalize([.5, .5, .5], [.5, .5, .5])\n",
    "])\n",
    "\n",
    "transform_val = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    v2.Normalize([.5, .5, .5], [.5, .5, .5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7257448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class doc_ds(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_paths[index]).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9210b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5a5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.DataFrame(columns=['doc_path', 'label'])\n",
    "df_t2 = pd.DataFrame(columns=df_t1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c246ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invoice', 'letter', 'email', 'news_article']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68437fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/invoice'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_rpath = os.path.relpath(os.path.join(train_path, classes[0]))\n",
    "class_rpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90535eff",
   "metadata": {},
   "source": [
    "### Загрузка файлов и разделение на `train`, `validation`, `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1900a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/invoice/ti16311152.tif</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/invoice/2084022630.tif</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/invoice/2063235294.tif</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/invoice/83545557.tif</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/invoice/2029370755.tif</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>data/train/news_article/tob14401.20.tif</td>\n",
       "      <td>news_article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>data/train/news_article/1003289799.tif</td>\n",
       "      <td>news_article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>data/train/news_article/2048367429.tif</td>\n",
       "      <td>news_article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>data/train/news_article/1002402701a.tif</td>\n",
       "      <td>news_article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>data/train/news_article/ton00509.94.tif</td>\n",
       "      <td>news_article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path        labels\n",
       "0           data/train/invoice/ti16311152.tif       invoice\n",
       "1           data/train/invoice/2084022630.tif       invoice\n",
       "2           data/train/invoice/2063235294.tif       invoice\n",
       "3             data/train/invoice/83545557.tif       invoice\n",
       "4           data/train/invoice/2029370755.tif       invoice\n",
       "...                                       ...           ...\n",
       "7995  data/train/news_article/tob14401.20.tif  news_article\n",
       "7996   data/train/news_article/1003289799.tif  news_article\n",
       "7997   data/train/news_article/2048367429.tif  news_article\n",
       "7998  data/train/news_article/1002402701a.tif  news_article\n",
       "7999  data/train/news_article/ton00509.94.tif  news_article\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvt_files_df = pd.DataFrame(columns=['path', 'labels'])\n",
    "for c in classes:\n",
    "    class_rpath = os.path.relpath(os.path.join(train_path, c))\n",
    "    temp_df = pd.DataFrame(columns=['path', 'labels'])\n",
    "    temp_df['path'] = class_rpath + '/' + pd.Series(os.listdir(os.path.join(train_path, c)))\n",
    "    temp_df['labels'] = c\n",
    "    \n",
    "    tvt_files_df = pd.concat((tvt_files_df, temp_df), axis=0, ignore_index=True)\n",
    "\n",
    "tvt_files_df\n",
    "\n",
    "# tvt_files_df # train, validate, test - data\n",
    "# tvt_files_df\n",
    "\n",
    "\n",
    "# invoice_files = pd.Series(os.listdir(os.path.join(train_path, classes[0])))\n",
    "# letter_files = pd.Series(os.listdir(os.path.join(train_path, classes[1])))\n",
    "\n",
    "# pd.concat((invoice_files, letter_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "321384ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ab1072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/invoice/ti16311152.tif</td>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/invoice/2084022630.tif</td>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/invoice/2063235294.tif</td>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/invoice/83545557.tif</td>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/invoice/2029370755.tif</td>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>data/train/news_article/tob14401.20.tif</td>\n",
       "      <td>news_article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>data/train/news_article/1003289799.tif</td>\n",
       "      <td>news_article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>data/train/news_article/2048367429.tif</td>\n",
       "      <td>news_article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>data/train/news_article/1002402701a.tif</td>\n",
       "      <td>news_article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>data/train/news_article/ton00509.94.tif</td>\n",
       "      <td>news_article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path        labels  label_id\n",
       "0           data/train/invoice/ti16311152.tif       invoice         1\n",
       "1           data/train/invoice/2084022630.tif       invoice         1\n",
       "2           data/train/invoice/2063235294.tif       invoice         1\n",
       "3             data/train/invoice/83545557.tif       invoice         1\n",
       "4           data/train/invoice/2029370755.tif       invoice         1\n",
       "...                                       ...           ...       ...\n",
       "7995  data/train/news_article/tob14401.20.tif  news_article         3\n",
       "7996   data/train/news_article/1003289799.tif  news_article         3\n",
       "7997   data/train/news_article/2048367429.tif  news_article         3\n",
       "7998  data/train/news_article/1002402701a.tif  news_article         3\n",
       "7999  data/train/news_article/ton00509.94.tif  news_article         3\n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvt_files_df['label_id'] = le.fit_transform(tvt_files_df['labels'])\n",
    "tvt_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216706eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvt_files_df['label_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73693c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5572637",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc_ds = doc_ds(tvt_files_df.path.to_list(), tvt_files_df.label_id.to_list(), transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049dd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(full_doc_ds, [.7, .15, .15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78e49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13cc9e",
   "metadata": {},
   "source": [
    "## fine-tuning модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d410d",
   "metadata": {},
   "source": [
    "### Загрузка модели, заморозка слоев, добавление поледнего линейного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90e46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilgiz/.cache/pypoetry/virtualenvs/ml-engineering-portfolio-PXL5yKuT-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62e7c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth\n",
      "hf_hub_id: timm/efficientnet_b0.ra_in1k\n",
      "architecture: efficientnet_b0\n",
      "tag: ra_in1k\n",
      "custom_load: False\n",
      "input_size: (3, 224, 224)\n",
      "fixed_input_size: False\n",
      "interpolation: bicubic\n",
      "crop_pct: 0.875\n",
      "crop_mode: center\n",
      "mean: (0.485, 0.456, 0.406)\n",
      "std: (0.229, 0.224, 0.225)\n",
      "num_classes: 1000\n",
      "pool_size: (7, 7)\n",
      "first_conv: conv_stem\n",
      "classifier: classifier\n",
      "license: apache-2.0\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "\n",
    "for param in model.parameters():    # Замораживаем слои\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 4)     # Добавляем новый полносвязный слой с активными градиентами\n",
    "\n",
    "\n",
    "# Обображаем параметры модели\n",
    "def show_model_info(model):\n",
    "    for k, v in model.default_cfg.items():\n",
    "        print(f'{k}: {v}')\n",
    "\n",
    "\n",
    "show_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cc2cdccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([p.requires_grad for p in model.parameters()][-5:])  # последние 5 тензоров — должны быть True (голова)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91831e1d",
   "metadata": {},
   "source": [
    "### Обучение головы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cabf70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "learning_rate = 1e-3    # 1e-3 - 3e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b1a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fc14452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb61fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion):\n",
    "    total_loss, correct_preds = 0, 0\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device); targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct_preds += (preds.argmax(dim=1) == targets).sum().item()\n",
    "        \n",
    "    return total_loss / len(loader.dataset), correct_preds / len(loader.dataset)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e70f7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    total_loss, correct_preds = 0, 0\n",
    "    torch.inference_mode()\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device); targets = targets.to(device)\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, targets)\n",
    "        \n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct_preds += (preds.argmax(dim=1) == targets).sum().item()  \n",
    "        \n",
    "    \n",
    "    return total_loss / len(loader.dataset), correct_preds / len(loader.dataset)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b35b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm    # Полоска загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5dcb5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/6 | Train accuracy: 0.8154%, Train loss: 0.5162 | Validation accuracy: 0.8008%, Validation loss: 0.5263\n",
      "Epoch: 2/6 | Train accuracy: 0.8325%, Train loss: 0.4786 | Validation accuracy: 0.8117%, Validation loss: 0.5056\n",
      "Epoch: 3/6 | Train accuracy: 0.8370%, Train loss: 0.4698 | Validation accuracy: 0.8158%, Validation loss: 0.4968\n",
      "Epoch: 4/6 | Train accuracy: 0.8387%, Train loss: 0.4540 | Validation accuracy: 0.8183%, Validation loss: 0.4896\n",
      "Epoch: 5/6 | Train accuracy: 0.8389%, Train loss: 0.4452 | Validation accuracy: 0.8267%, Validation loss: 0.4753\n",
      "Epoch: 6/6 | Train accuracy: 0.8379%, Train loss: 0.4474 | Validation accuracy: 0.8292%, Validation loss: 0.4725\n"
     ]
    }
   ],
   "source": [
    "total_train_acc, total_val_acc = [], []\n",
    "total_train_loss, total_val_loss = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss, train_acc = train_model(model, train_dl, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model, val_dl, criterion)\n",
    "    \n",
    "    total_train_acc.append(train_acc); total_train_loss.append(train_loss)\n",
    "    total_val_acc.append(val_acc); total_val_loss.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch: {e+1}/{epochs} | Train accuracy: {train_acc:.4f}%, Train loss: {train_loss:.4f} | Validation accuracy: {val_acc:.4f}%, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/efficientnet_b0_doc_classifier_head_only.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa5dad",
   "metadata": {},
   "source": [
    "### Обучение всей модели с 4 выходами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec78a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1280, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=4)\n",
    "model.load_state_dict(torch.load('models/efficientnet_b0_doc_classifier_head_only.pth', weights_only=True))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "558f1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc85fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 1e-5     # 1e-5 - 5e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e41b5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 | Train accuracy: 0.8514%, Train loss: 0.4154 | Validation accuracy: 0.8650%, Validation loss: 0.3802\n",
      "Epoch: 2/10 | Train accuracy: 0.8686%, Train loss: 0.3736 | Validation accuracy: 0.8717%, Validation loss: 0.3765\n",
      "Epoch: 3/10 | Train accuracy: 0.8755%, Train loss: 0.3455 | Validation accuracy: 0.8550%, Validation loss: 0.3933\n",
      "Epoch: 4/10 | Train accuracy: 0.8768%, Train loss: 0.3436 | Validation accuracy: 0.8825%, Validation loss: 0.3452\n",
      "Epoch: 5/10 | Train accuracy: 0.8859%, Train loss: 0.3168 | Validation accuracy: 0.8858%, Validation loss: 0.3291\n",
      "Epoch: 6/10 | Train accuracy: 0.8855%, Train loss: 0.3037 | Validation accuracy: 0.8933%, Validation loss: 0.3343\n",
      "Epoch: 7/10 | Train accuracy: 0.8968%, Train loss: 0.2918 | Validation accuracy: 0.8892%, Validation loss: 0.3190\n",
      "Epoch: 8/10 | Train accuracy: 0.9016%, Train loss: 0.2777 | Validation accuracy: 0.8917%, Validation loss: 0.3123\n",
      "Epoch: 9/10 | Train accuracy: 0.9061%, Train loss: 0.2667 | Validation accuracy: 0.8958%, Validation loss: 0.2983\n",
      "Epoch: 10/10 | Train accuracy: 0.9055%, Train loss: 0.2543 | Validation accuracy: 0.8942%, Validation loss: 0.2901\n"
     ]
    }
   ],
   "source": [
    "total_train_acc, total_val_acc = [], []\n",
    "total_train_loss, total_val_loss = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss, train_acc = train_model(model, train_dl, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model, val_dl, criterion)\n",
    "    \n",
    "    total_train_acc.append(train_acc); total_train_loss.append(train_loss)\n",
    "    total_val_acc.append(val_acc); total_val_loss.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch: {e+1}/{epochs} | Train accuracy: {train_acc:.4f}%, Train loss: {train_loss:.4f} | Validation accuracy: {val_acc:.4f}%, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/efficentnet_b0_docclassifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af970d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caec457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c235c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d557743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c57dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac8593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc337d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5f5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-engineering-portfolio-PXL5yKuT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
