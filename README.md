# Vision Transformer for CIFAR-10

Implementation of a Vision Transformer (ViT) from scratch in PyTorch for image classification on the CIFAR-10 dataset.

## ğŸ“Š Results
- **Test Accuracy**: 63.4%
- **Model**: Custom ViT (patch size=4, embed_dim=64, depth=6, num_heads=4)
- **Training**: 10 epochs, AdamW, lr=3e-4
- **Hardware**: Trained on GPU

> Note: This is a minimal implementation to demonstrate understanding of ViT architecture. Performance can be improved with data augmentation, longer training, and hyperparameter tuning.

## â–¶ï¸ How to Use

### Install dependencies
```bash
poetry install
```

## Run Inference
```
poetry run python predict.py --image cat_test.jpg --model vit_model2.pth
cat
```


## ğŸ“ Project Structure
* `model.py` â€” ViT implementation
* `train.py` â€” training loop
* `predict.py` â€” CLI inference
* `config.py` â€” hyperparameters
* `utils.py` â€” helper functions (seed, device)